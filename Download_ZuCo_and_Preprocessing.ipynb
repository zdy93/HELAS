{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Download_ZuCo_and_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RSR9Kpw6Qs0E"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbs2ODl5jQ_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io as sio\n",
        "import os\n",
        "import wget\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "# import io\n",
        "import string\n",
        "import re\n",
        "import math\n",
        "import struct"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSR9Kpw6Qs0E",
        "colab_type": "text"
      },
      "source": [
        "# Download and Preporcess ZUGO Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUzuj8Waj_fx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "45030e63-c244-4475-85ba-1b1c82b767db"
      },
      "source": [
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6aa3ee2b5f000d45028e?action=download&direct&version=2',\n",
        "              'resultsZAB_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6c17ee2b5f000f44d94e?action=download&direct&version=2',\n",
        "              'resultsZDM_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6a39ee2b5f000f44d824?action=download&direct&version=3',\n",
        "              'resultsZDN_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6b96ee2b5f000e44ce1e?action=download&direct&version=2',\n",
        "              'resultsZGW_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6bd393d197000f2f2903?action=download&direct&version=2',\n",
        "              'resultsZJM_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6c3fee2b5f000d4503ef?action=download&direct&version=2',\n",
        "              'resultsZJN_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6a8f93d197000e2efec6?action=download&direct&version=2',\n",
        "              'resultsZJS_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6bd793d197000f2f2907?action=download&direct&version=2',\n",
        "              'resultsZKB_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6abe93d197000f2f280d?action=download&direct&version=2',\n",
        "              'resultsZKH_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6beeee2b5f001044ca15?action=download&direct&version=2',\n",
        "              'resultsZKW_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6b9593d197000e2eff90?action=download&direct&version=2',\n",
        "              'resultsZMG_SR.mat')\n",
        "wget.download('https://files.osf.io/v1/resources/q3zws/providers/osfstorage/5afd6a9f93d197000e2efed0?action=download&direct&version=2',\n",
        "              'resultsZPH_SR.mat')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'resultsZPH_SR.mat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEcqLr91sqBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "d32dfb94-d351-4520-d603-bebc7d0052a4"
      },
      "source": [
        "file_list = []\n",
        "for i in os.listdir():\n",
        "    if i.find('results') != -1:\n",
        "        print(i)\n",
        "        file_list.append(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resultsZJN_SR.mat\n",
            "resultsZDN_SR.mat\n",
            "resultsZJM_SR.mat\n",
            "resultsZKW_SR.mat\n",
            "resultsZMG_SR.mat\n",
            "resultsZKH_SR.mat\n",
            "resultsZGW_SR.mat\n",
            "resultsZKB_SR.mat\n",
            "resultsZDM_SR.mat\n",
            "resultsZJS_SR.mat\n",
            "resultsZAB_SR.mat\n",
            "resultsZPH_SR.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkdLQB1ai1gZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "80bc5ac2-8cc7-4460-f95c-5496882b288f"
      },
      "source": [
        "### HOW TO READ MATLAB FILE IN PYTHON 3 ###\n",
        "\n",
        "# set correct file name\n",
        "file_name = \"./resultsZDM_SR.mat\"\n",
        "\n",
        "# index of the array `data` is the number of sentence\n",
        "data = sio.loadmat(file_name, squeeze_me=True, struct_as_record=False)['sentenceData']\n",
        "\n",
        "# get all field names for sentence data\n",
        "print(data[0]._fieldnames)\n",
        "\n",
        "# example: print sentence\n",
        "print(data[0].content)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['content', 'rawData', 'mean_t1', 'mean_t2', 'mean_a1', 'mean_a2', 'mean_b1', 'mean_b2', 'mean_g1', 'mean_g2', 'mean_t1_sec', 'mean_t2_sec', 'mean_a1_sec', 'mean_a2_sec', 'mean_b1_sec', 'mean_b2_sec', 'mean_g1_sec', 'mean_g2_sec', 'mean_t1_diff', 'mean_t2_diff', 'mean_a1_diff', 'mean_a2_diff', 'mean_b1_diff', 'mean_b2_diff', 'mean_g1_diff', 'mean_g2_diff', 'mean_t1_diff_sec', 'mean_t2_diff_sec', 'mean_a1_diff_sec', 'mean_a2_diff_sec', 'mean_b1_diff_sec', 'mean_b2_diff_sec', 'mean_g1_diff_sec', 'mean_g2_diff_sec', 'word', 'omissionRate', 'allFixations', 'wordbounds', 'answer_mean_t1', 'answer_mean_t2', 'answer_mean_a1', 'answer_mean_a2', 'answer_mean_b1', 'answer_mean_b2', 'answer_mean_g1', 'answer_mean_g2', 'answer_mean_t1_diff', 'answer_mean_t2_diff', 'answer_mean_a1_diff', 'answer_mean_a2_diff', 'answer_mean_b1_diff', 'answer_mean_b2_diff', 'answer_mean_g1_diff', 'answer_mean_g2_diff']\n",
            "Presents a good case while failing to provide a reason for us to care beyond the very basic dictums of human decency.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_nr_ncrp-Iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zuco_text = np.array([data[i].content for i in range(len(data))])\n",
        "np.save('data/zuco_text.npy', zuco_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNWJd4yHiN-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_document(document):\n",
        "    document = document.lower()\n",
        "    table = str.maketrans({key: None for key in string.punctuation})\n",
        "    cleaned_document = document.translate(table)  \n",
        "    return cleaned_document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qb0yKQ0ig1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zuco_text = np.load('data/zuco_text.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBDxfic4iSdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_reviews = [clean_document(doc) for doc in zuco_text]\n",
        "zuco_new_text = np.array(cleaned_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4wcIxnVi24Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "492c1d8b-ad5b-4cf2-fdb7-48f361141f37"
      },
      "source": [
        "print(zuco_new_text[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "presents a good case while failing to provide a reason for us to care beyond the very basic dictums of human decency\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYnz4i1hihRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('data/zuco_new_text.npy', zuco_new_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yeGI2DvsV4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5772b03-19e7-415d-e057-4c3d2ff2551e"
      },
      "source": [
        "len_list = [data[i].word.shape[0] for i in range(len(data))]\n",
        "print('Average sentence length: %s'%np.mean(len_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average sentence length: 17.8225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i66wRv1tnXi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "103c83ab-f46c-4d5f-c8b5-d0fa03d6172e"
      },
      "source": [
        "# example: get omission rate of first sentence\n",
        "omission_rate = data[0].omissionRate\n",
        "print(omission_rate)\n",
        "\n",
        "# get word level data\n",
        "word_data = data[0].word\n",
        "\n",
        "# get names of all word features\n",
        "# index of the array `word_data` is the number of the word\n",
        "print(word_data[0]._fieldnames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22727272727272727\n",
            "['content', 'fixPositions', 'nFixations', 'meanPupilSize', 'rawEEG', 'rawET', 'FFD', 'FFD_pupilsize', 'FFD_t1', 'FFD_t2', 'FFD_a1', 'FFD_a2', 'FFD_b1', 'FFD_b2', 'FFD_g1', 'FFD_g2', 'FFD_t1_diff', 'FFD_t2_diff', 'FFD_a1_diff', 'FFD_a2_diff', 'FFD_b1_diff', 'FFD_b2_diff', 'FFD_g1_diff', 'FFD_g2_diff', 'TRT', 'TRT_pupilsize', 'TRT_t1', 'TRT_t2', 'TRT_a1', 'TRT_a2', 'TRT_b1', 'TRT_b2', 'TRT_g1', 'TRT_g2', 'TRT_t1_diff', 'TRT_t2_diff', 'TRT_a1_diff', 'TRT_a2_diff', 'TRT_b1_diff', 'TRT_b2_diff', 'TRT_g1_diff', 'TRT_g2_diff', 'GD', 'GD_pupilsize', 'GD_t1', 'GD_t2', 'GD_a1', 'GD_a2', 'GD_b1', 'GD_b2', 'GD_g1', 'GD_g2', 'GD_t1_diff', 'GD_t2_diff', 'GD_a1_diff', 'GD_a2_diff', 'GD_b1_diff', 'GD_b2_diff', 'GD_g1_diff', 'GD_g2_diff', 'GPT', 'GPT_pupilsize', 'GPT_t1', 'GPT_t2', 'GPT_a1', 'GPT_a2', 'GPT_b1', 'GPT_b2', 'GPT_g1', 'GPT_g2', 'GPT_t1_diff', 'GPT_t2_diff', 'GPT_a1_diff', 'GPT_a2_diff', 'GPT_b1_diff', 'GPT_b2_diff', 'GPT_g1_diff', 'GPT_g2_diff', 'SFD', 'SFD_pupilsize', 'SFD_t1', 'SFD_t2', 'SFD_a1', 'SFD_a2', 'SFD_b1', 'SFD_b2', 'SFD_g1', 'SFD_g2', 'SFD_t1_diff', 'SFD_t2_diff', 'SFD_a1_diff', 'SFD_a2_diff', 'SFD_b1_diff', 'SFD_b2_diff', 'SFD_g1_diff', 'SFD_g2_diff']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU4nrujCrBHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "c9e1df63-7b12-4b84-c57f-1027dc58dcee"
      },
      "source": [
        "# example: get first word\n",
        "print(word_data[0].content)\n",
        "\n",
        "# example: get number of fixations of first word\n",
        "print(word_data[0].nFixations)\n",
        "print(word_data[1].nFixations)\n",
        "\n",
        "# example: get total reading time\n",
        "print(word_data[0].TRT)\n",
        "print(word_data[1].TRT)\n",
        "\n",
        "# get MEAN FIX DUR of first word\n",
        "print(word_data[0].TRT/word_data[0].nFixations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Presents\n",
            "4\n",
            "3\n",
            "669\n",
            "295\n",
            "167.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbF84luWrmeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_data_list = [data[i].word for i in range(len(data))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4_vS1Zor835",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e037b99f-d966-4ee2-bf39-7497025b24b8"
      },
      "source": [
        "max_len = max([len(word_data_list[i]) for i in range(len(word_data_list))])\n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FryBymgAuZTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mfd_big_array_list = []\n",
        "for file_name in file_list:\n",
        "    data = sio.loadmat(file_name, squeeze_me=True, struct_as_record=False)['sentenceData']\n",
        "    word_data_list = [data[i].word for i in range(len(data))]\n",
        "    mfd_big_list = []\n",
        "    for word_data in word_data_list:\n",
        "        mfd_list = []\n",
        "        if type(word_data) is float:\n",
        "            mfd_list = [np.nan] * 43\n",
        "        else:\n",
        "            word_data_len = len(word_data)\n",
        "            for wi in range(word_data_len):\n",
        "                if type(word_data[wi].TRT) is not int:\n",
        "                    mfd = 0.0\n",
        "                else:\n",
        "                    mfd = word_data[wi].TRT/word_data[wi].nFixations\n",
        "                mfd_list.append(mfd)\n",
        "            if word_data_len < 43:\n",
        "                mfd_list += [0.0] * (43 - len(mfd_list))\n",
        "        mfd_big_list.append(mfd_list)\n",
        "    mfd_big_array = np.asarray(mfd_big_list)\n",
        "    mfd_big_array_list.append(mfd_big_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_ojgBdQw7de",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mfd_array = np.nanmean(np.asarray(mfd_big_array_list), axis=0)\n",
        "np.save('data/mfd_scores.npy', mfd_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs_4KI__Q0m7",
        "colab_type": "text"
      },
      "source": [
        "# Convert to Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VysD5WCln98Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zuco_new_text = np.load('data/zuco_new_text.npy')\n",
        "mfd_scores = np.load('data/mfd_scores.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao-kfkvJoH7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "69e96d50-2e61-4bb0-ec7d-c83432882644"
      },
      "source": [
        "max_words = 73 #num_words\n",
        "\n",
        "output_zuco = []\n",
        "for review in zuco_new_text:\n",
        "    words = review.split()\n",
        "    words_mapped = [0]* max_words\n",
        "    \n",
        "    length = len(words)\n",
        "    if(length<max_words):\n",
        "        #print('We should never see this print')\n",
        "        for i in range(0,length):\n",
        "            words_mapped[i] = embeddings_index.get(words[i], embeddings_index['unk'])\n",
        "        for i in range(length,max_words):\n",
        "            words_mapped[i] =  embeddings_index['unk']\n",
        "    elif (length>max_words):\n",
        "        print('We should never see this print either')\n",
        "    else:\n",
        "        for i in range(0,max_words):\n",
        "            words_mapped[i] = embeddings_index.get(words[i], embeddings_index['unk'])\n",
        "            \n",
        "    output_zuco.append(words_mapped)\n",
        "    \n",
        "output_zuco = np.array(output_zuco)\n",
        "print(output_zuco.shape)\n",
        "print(output_zuco[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400, 73, 100)\n",
            "[[-0.49862   0.28541   0.35966  ... -0.48704   0.78987   0.7194  ]\n",
            " [-0.27086   0.044006 -0.02026  ... -0.4923    0.63687   0.23642 ]\n",
            " [-0.030769  0.11993   0.53909  ... -0.52878   0.17584   1.065   ]\n",
            " ...\n",
            " [ 0.027166 -0.1762   -0.19623  ... -0.37226  -0.28782  -0.015834]\n",
            " [ 0.027166 -0.1762   -0.19623  ... -0.37226  -0.28782  -0.015834]\n",
            " [ 0.027166 -0.1762   -0.19623  ... -0.37226  -0.28782  -0.015834]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJKtDuRccvyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('data/zuco_gloves.npy', output_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU380KjUj2DX",
        "colab_type": "text"
      },
      "source": [
        "# Convert To PubMed Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M47z5NTwkEli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ef66eea9-bc67-4472-c4fb-0bf8de7c7a89"
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "model = KeyedVectors.load_word2vec_format('medical_data/PubMed-w2v.bin', binary=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYn7zz3XI-Af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zuco_new_text = np.load('data/zuco_new_text.npy')\n",
        "mfd_scores = np.load('data/mfd_scores.npy')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2A84OYoN609",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_reviews = [zuco_new_text[i].split() for i in range(len(zuco_new_text))]\n",
        "baseline_att = mfd_scores"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orv4q20XkrsC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "8bca6e17-3a44-4207-be7c-864aac25ec5b"
      },
      "source": [
        "max_words = 43 #num_words\n",
        "num_unk = 0\n",
        "num_normal = 0 \n",
        "output_reviews = []\n",
        "att_labels =[]\n",
        "\n",
        "for words,attscr in zip(cleaned_reviews, baseline_att):\n",
        "    words_mapped = [0]* max_words\n",
        "    att_mapped =[0]* max_words\n",
        "    length = len(words)\n",
        "    if(length<max_words):\n",
        "        for i in range(0,length):\n",
        "            att_mapped[i] = attscr[i]\n",
        "            try:\n",
        "                words_mapped[i] = model[words[i]]\n",
        "                num_normal += 1\n",
        "            except:\n",
        "                words_mapped[i] = model['unk']\n",
        "                num_unk += 1\n",
        "        for i in range(length,max_words):\n",
        "            words_mapped[i] =  model['unk']\n",
        "            att_mapped[i] = 0\n",
        "    else:\n",
        "        for i in range(0,max_words):\n",
        "            att_mapped[i] = attscr[i]\n",
        "            try:\n",
        "                words_mapped[i] = model[words[i]]\n",
        "                num_normal += 1\n",
        "            except:\n",
        "                words_mapped[i] = model['unk']\n",
        "                num_unk += 1\n",
        "            \n",
        "    output_reviews.append(words_mapped)\n",
        "    att_labels.append(att_mapped)\n",
        "    \n",
        "output_reviews  = np.array(output_reviews)\n",
        "cleaned_reviews = np.array(cleaned_reviews)\n",
        "att_labels      = np.array(att_labels)\n",
        "\n",
        "print('num_normal', num_normal)\n",
        "print('num_unk',num_unk)\n",
        "\n",
        "print(output_reviews.shape)\n",
        "print(cleaned_reviews.shape)\n",
        "print(att_labels.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_normal 6698\n",
            "num_unk 376\n",
            "(400, 43, 200)\n",
            "(400,)\n",
            "(400, 43)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GJztkHemes_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('medical_data/zuco_pubmed.npy', output_reviews)\n",
        "np.save('medical_data/zuco_pubmed_att_labels.npy', att_labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}